{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6: Confidence Intervals, the Normal Distribution, and the Central Limit Theorem\n",
    "\n",
    "## Due Thursday, March 9th at 11:59PM\n",
    "\n",
    "Welcome to Homework 6, the last homework of the quarter! This week, we will cover confidence intervals, the normal distribution, and the Central Limit Theorem. You can find additional help on these topics in the following readings:\n",
    "\n",
    "* [CIT 13.3](https://inferentialthinking.com/chapters/13/3/Confidence_Intervals.html): Confidence Intervals\n",
    "* [CIT 13.4](https://inferentialthinking.com/chapters/13/4/Using_Confidence_Intervals.html): Using Confidence Intervals\n",
    "* [CIT 14.2](https://www.inferentialthinking.com/chapters/14/2/Variability.html): Variability, Standard Deviation, Standard Units, Chebyshev's Bounds\n",
    "* [CIT 14.3](https://www.inferentialthinking.com/chapters/14/3/SD_and_the_Normal_Curve.html): The Standard Deviation (SD) and the Normal Curve \n",
    "* [CIT 14.4](https://www.inferentialthinking.com/chapters/14/4/Central_Limit_Theorem.html): The Central Limit Theorem\n",
    "* [CIT 14.5](https://www.inferentialthinking.com/chapters/14/5/Variability_of_the_Sample_Mean.html): The Variability of the Sample Mean\n",
    "* [CIT 14.6](https://inferentialthinking.com/chapters/14/6/Choosing_a_Sample_Size.html): Choosing a Sample Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "You are given six slip days throughout the quarter to extend deadlines. See the syllabus for more details. With the exception of using slip days, late work will not be accepted unless you have made special arrangements with your instructor.\n",
    "\n",
    "**Important**: For homeworks, the `otter` tests don't usually tell you that your answer is correct. More often, they help catch careless mistakes. It's up to you to ensure that your answer is correct. If you're not sure, ask someone (not for the answer, but for some guidance about your approach). These are great questions for office hours (see the schedule on the [Calendar](https://dsc10.com/calendar)) or EdStem. Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change this cell, but do make sure to run it\n",
    "import babypandas as bpd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import otter\n",
    "grader = otter.Notebook()\n",
    "\n",
    "from IPython.display import IFrame\n",
    "def show_clt_slides():\n",
    "    src = \"https://docs.google.com/presentation/d/e/2PACX-1vTcJd3U1H1KoXqBFcWGKFUPjZbeW4oiNZZLCFY8jqvSDsl4L1rRTg7980nPs1TGCAecYKUZxH5MZIBh/embed?start=false&loop=false&delayms=3000\"\n",
    "    width = 700\n",
    "    height = 370\n",
    "    display(IFrame(src, width, height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hotels in Europe \n",
    "Suppose you and your friends want to spend a peaceful week in Europe during spring break, and you have been considering four cities to visit: Sarajevo (in Bosnia and Herzegovina), Zagreb (in Croatia), Belgrade (in Serbia), and Ljubljana (in Slovenia). Sadly, you only have one week for spring break, so it might be too short to visit all four cities. As college students, you have a limited budget and are wondering which city has the cheapest hotels.\n",
    "\n",
    "You gathered hotel data from the booking website [www.booking.com](www.booking.com) for the four cities above. The DataFrame `hotels` below contains a **sample** of all the hotels in the four cities above. Each row corresponds to a particular hotel. We have information on the `'Hotel name'`, the `'City'`, the `'Price(BAM)'` for a one night stay, in  the currency of Bosnia and Herzegovina, the `'Hotel star rating'` from 1 to 5, and the `'Customer rating'` from 1 to 10 . Now it‚Äôs time to analyze the price and rating of hotels for each city!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels = bpd.read_csv('data/hotels.csv')\n",
    "hotels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1.** Let's start by determining the mean price for each city. Create a DataFrame called `city_means`, indexed by `'City'`, with one column called `'Price(BAM)'` that contains the mean price for that city, in the original currency. Sort `city_means` in descending order of `'Price(BAM)'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_means = ...\n",
    "city_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2.** Sarajevo seems to have the most affordable hotels based on the data we have access to. However the data we have access to is only a sample of all hotels in four cities, and thus the mean price for Sarajevo that we computed above is only a sample statistic, not a population parameter.\n",
    "\n",
    "Produce 1,000 bootstrapped estimates for the mean price of **all** hotels in the city of Sarajevo. Store the estimates in the `Sarajevo_averages` array. Then, use the `Sarajevo_averages` array to calculate an approximate 99% confidence interval for the true mean price. Assign the endpoints of your interval to `lower_bound` and `upper_bound`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sarajevo_averages = ...\n",
    "\n",
    "\n",
    "lower_bound = ...\n",
    "upper_bound = ...\n",
    "\n",
    "# Display the estimates in a histogram.\n",
    "bpd.DataFrame().assign(Estimated_Average_Price=Sarajevo_averages).plot(kind='hist', density=True, ec='w', figsize=(10, 5), title=\"Sarajevo\");\n",
    "plt.plot([lower_bound, upper_bound], [0, 0], color='gold', linewidth=10, label='99% confidence interval');\n",
    "\n",
    "# Don't change the line below (though you will need to copy and change it in 1.3)\n",
    "city_name = 'Sarajevo_averages'\n",
    "f'A 99% confidence interval for average hotel price of {city_name} is [{lower_bound}, {upper_bound}]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3.** You want to create a similar histogram for each of the other cities, and also calculate the corresponding confidence intervals, but repeating the process above 4 times would be redundant. Let's try to generalize what we did in Question 1.2 to work for any city! \n",
    "\n",
    "Create a function called `ci_and_hist`, which takes in a city name as a string, and:\n",
    "1. **Plots the histogram** of 1,000 bootstrapped estimates for the city's mean hotel price.\n",
    "2. **Returns** a string describing the approximate 99% confidence interval for the city's mean hotel price, formatted in the same way as the string displayed for Sarajevo in Question 1.2. \n",
    "\n",
    "*Notes*: \n",
    "- Make sure your function both plots a histogram and **returns** a string. For example, `ci_and_hist('Ljubljana')` should return a string that starts with `'A 99% confidence interval for average hotel price of ... is'` where ... is the city name.\n",
    "- The string displayed at the end of 1.2 was created using a feature of Python called f-strings. You'll need to copy and change that f-string expression. Read [this article](https://realpython.com/python-f-strings/#simple-syntax) for more details about f-strings if you're interested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ci_and_hist(city_name):\n",
    "    ...\n",
    "    \n",
    "# Example calls to the function. Don't change the lines below.\n",
    "Ljubljana_string = ci_and_hist('Ljubljana')\n",
    "print(Ljubljana_string)\n",
    "Zagreb_string = ci_and_hist('Zagreb')\n",
    "print(Zagreb_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4.** One of your travel companions claims that hotels in Belgrade are more expensive than our sample of data suggests. In our sample, the mean price for hotels in Belgrade is about 172 BAM. She claims that since our price data is only a sample of the full population of hotels, the actual mean price of Belgrade hotels could be 200 BAM. You decide to perform a hypothesis test for the following pair of hypotheses:\n",
    "\n",
    "- **Null Hypothesis**: The mean price of hotels in Belgrade is 200 BAM.\n",
    "- **Alternative Hypothesis**: The mean price of hotels in Belgrade is not 200 BAM.\n",
    "\n",
    "Run the cell below to use the `ci_and_hist` function you defined above to calculate an approximate 99% confidence interval for the mean price of the `'Belgrade'` city. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_and_hist('Belgrade') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you reject the null hypothesis at a 0.01 p-value cutoff? Assign 1, 2, 3, or 4 to `q1_4`.\n",
    "1. No, because the confidence interval includes 200.\n",
    "1. No, because the confidence interval doesn't include 200.\n",
    "1. Yes, because the confidence interval includes 200.\n",
    "1. Yes, because the confidence interval doesn't include 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_4 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Testing the Central Limit Theorem: Coin Flips and Airbnb Prices üõèÔ∏è\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Central Limit Theorem tells us that the probability distribution of the sum or mean of a large random sample drawn with replacement is roughly normal, *regardless of the distribution of the population from which the sample is drawn*.\n",
    "\n",
    "That's a pretty big claim, but the theorem doesn't stop there. It further states that, if we're using the mean as our statistic, the standard deviation of this normal distribution is given by $$\\text{SD of Distribution of Possible Sample Means} = \\frac{\\text{Population SD}}{\\sqrt{\\text{sample size}}}$$\n",
    "\n",
    " In other words, suppose we start with *any distribution* that has standard deviation $\\sigma$, take a sample of size $n$ (where $n$ is a large number) from that distribution with replacement, and compute the mean of that sample. If we repeat this procedure many times, then those sample means will have a normal distribution with standard deviation $\\frac{\\sigma}{\\sqrt{n}}$.\n",
    "\n",
    "That's an even bigger claim than the first one! The proof of the theorem is beyond the scope of this class, but we've seen examples in lecture of this formula in action, such as when we looked at flight delay data.\n",
    "\n",
    "Run the cell below to see a short presentation that describes the CLT at a high level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_clt_slides()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will be exploring some new data to see the CLT in action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1.** The CLT only applies when sample sizes are \"sufficiently large.\" This isn't a very precise statement. Is 10 large?  How about 50?  The truth is that it depends both on the original population distribution and just how \"normal\" you want the result to look. Let's use a simulation to get a feel for how the distribution of the sample mean changes as the sample size increases.\n",
    "\n",
    "Consider a coin flip. If we say heads is $1$ and tails is $0$, then there's a 50% chance of getting a $1$ and a 50% chance of getting a $0$, which is definitely not a normal distribution.  The mean of these $1$s and $0$s for several coin tosses is equal to the proportion of heads in those coin tosses, so the CLT should apply if we compute the sample proportion of heads many times.\n",
    "\n",
    "Write a function called `simulate_sample_n` that takes in a sample size `n`. It should repeat, 5000 times, the process of:\n",
    "- simulating `n` flips of a fair coin, and\n",
    "- counting the proportion of flips that were heads.\n",
    "\n",
    "`simulate_sample_n` should return an array that contains 5000 sample proportions, using the process outlined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_sample_n(n):\n",
    "    ...\n",
    "simulate_sample_n(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will use the function you just defined to plot the empirical distribution of the sample mean for several different sample sizes. We saw something similar in [Lecture 22](https://dsc10.com/resources/lectures/lec22/lec22.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(-0.01, 1.05, 0.02)\n",
    "\n",
    "for sample_size in np.array([2, 5, 10, 20, 50, 100, 200, 400]):\n",
    "    bpd.DataFrame().assign(**{'Sample_Size:{}'.format(sample_size) : simulate_sample_n(sample_size)}) \\\n",
    "                   .plot(kind='hist', density=True, ec='w', bins=bins, \n",
    "                         title=f'Sample Size {sample_size}', legend=None, figsize=(5, 3));\n",
    "    plt.xlim(-0.01, 1.05)\n",
    "    plt.ylim(0, 25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that even for samples of size 10, the distribution of sample proportions looks roughly bell-shaped. When we increase the sample size to 50, the resulting distribution looks quite bell-shaped. Note also that as the sample sizes increases, the distributions of sample proportions become narrower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will test the second claim of the CLT: that the SD of the distribution of the sample mean is the SD of the original distribution, divided by the square root of the sample size.\n",
    "\n",
    "$$\\text{SD of Distribution of Possible Sample Means} = \\frac{\\text{Population SD}}{\\sqrt{\\text{sample size}}}$$\n",
    "\n",
    "Below, we will read in a dataset of Airbnb prices in Manhattan, New York üèôÔ∏è üöï. We'll treat this DataFrame as our population, and we'll take samples directly from it. We've computed the standard deviation of the Airbnb prices for you; you will need to use it in the next question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_pop = bpd.read_csv('data/airbnb.csv')\n",
    "airbnb_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_pop_std = np.std(airbnb_pop.get('price'))\n",
    "airbnb_pop_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.** Write a function called `predict_sd` that takes in a sample size `n`. It returns the predicted standard deviation (according to the CLT) of the sample mean's distribution, for samples of size `n` taken from the Airbnb price data.\n",
    "\n",
    "*Hint*: **Do not** use or modify your code from `simulate_sample_n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sd(n):\n",
    "    ...\n",
    "\n",
    "predict_sd(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3.** Write a function called `empirical_sd` that takes in a sample size `n`, draws 1,000 samples of size `n` from the Airbnb prices data set with replacement, and returns the **standard deviation of the distribution of the sample means** of those 1,000 samples.\n",
    "\n",
    "*Hint*: This function will be similar to the `simulate_sample_n` function you wrote earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_sd(n): \n",
    "    sample_means = np.array([])\n",
    "    ...\n",
    "    return np.std(sample_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will plot the predicted SDs (computed by your `predict_sd` function) and empirical SDs (computed by your `empirical_sd` function) for various sample sizes. It may take a few moments to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_df = bpd.DataFrame().assign(Sample_Size = np.arange(1, 101, 10))\n",
    "predicted = sd_df.get('Sample_Size').apply(predict_sd)\n",
    "empirical = sd_df.get('Sample_Size').apply(empirical_sd)\n",
    "sd_df = sd_df.assign(Predicted_SD = predicted, Empirical_SD = empirical)\n",
    "ax = sd_df.plot(kind='scatter',x='Sample_Size', y='Empirical_SD',label='Empirical_SD', color='red', alpha=0.6, s=100, figsize=(10, 5));\n",
    "ax = sd_df.plot(kind='scatter',x='Sample_Size', y='Predicted_SD',label='Predicted_SD', color='blue', alpha=0.6, s=100, ax=ax)\n",
    "ax.set_ylabel('Standard Deviation');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the formula $$\\text{SD of Distribution of Possible Sample Means} = \\frac{\\text{Population SD}}{\\sqrt{\\text{sample size}}}$$ matches what we see in practice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Worst OREO Flavor ü•ïüéÇ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OREO is a brand of sandwich cookie üç™, typically with two chocolate wafers separated by a vanilla creme filling. It is one of the most popular cookies in the US, and in addition to the traditional chocolate with vanilla creme OREO,  [many creative varieties](https://en.wikipedia.org/wiki/List_of_Oreo_varieties) have been produced, including Mint, Gingerbread, and Caramel Coconut. However, it seems that not all the flavors are as well-loved as the original. According to a survey conducted by the food lovers' website Mashed, Americans voted Carrot Cake ü•ïüéÇ to be the [worst OREO flavor](https://www.mashed.com/467541/nearly-25-agree-this-is-the-worst-oreo-flavor/).\n",
    "\n",
    "<img src='images/carrot_cake.png' width='300'>\n",
    "\n",
    "Vanessa, a Carrot Cake OREO lover at UCSD, was disappointed by this survey üò≠, and wanted to see whether her peers also agree that Carrot Cake is the worst flavor. She polled a uniform random sample of all 41,065 UCSD students, and determined that, out of the 640 randomly sampled students, 160 agreed that Carrot Cake is the worst OREO flavor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell, but don't change it.\n",
    "survey = bpd.DataFrame().assign(\n",
    "    Opinion=np.array([\"Disgree\", \"Agree\"]),\n",
    "    Count=np.array([480, 160]))\n",
    "sample_size = survey.get(\"Count\").sum()\n",
    "survey_results = survey.assign(\n",
    "    Proportion=survey.get(\"Count\") / sample_size)\n",
    "survey_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, she used 1,000 bootstrap resamples to compute a confidence interval for the proportion of all UCSD students who agreed that Carrot Cake is the worst OREO flavor.  Run the next cell to see the empirical distribution of `'Agree'` proportions in the 1,000 resamples.\n",
    "\n",
    "Note that we're using `np.random.multinomial` to do the resampling here, since each element of the resample is either 1 (agree) or 0 (disagree) with known probabilities. This accomplishes the same thing as using `.sample` with `replace=True`, but is much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_proportions = np.array([])\n",
    "for i in np.arange(1000):\n",
    "    resample = np.random.multinomial(sample_size, survey_results.get('Proportion')) / sample_size\n",
    "    boot_proportions = np.append(boot_proportions, resample[1])\n",
    "bpd.DataFrame().assign(boot_proportions = boot_proportions).plot(kind='hist', density=True, ec='w', bins=np.arange(0.15, 0.45, .01), figsize=(10,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall, the Central Limit Theorem says\n",
    "\n",
    "$$\\text{SD of Distribution of Possible Sample Means} = \\frac{\\text{Population SD}}{\\sqrt{\\text{sample size}}}$$\n",
    "\n",
    "Furthermore, in any collection of numbers where the only unique values are 0 and 1, there is a simple formula for the standard deviation of the collection:\n",
    "\n",
    "$$\\text{SD of Collection of 0s and 1s} = \\sqrt{(\\text{Proportion of 0s in Collection}) \\times (\\text{Proportion of 1s in Collection})}$$\n",
    "\n",
    "Note that samples and populations are both possible examples of \"collections.\" \n",
    "\n",
    "(You're not responsible for deriving this formula, but if you're curious, it's possible to do so just by using the definition of standard deviation and a little algebra!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1.**\n",
    "**Without accessing the data in `boot_proportions` in any way**, compute an approximation of the standard deviation of the array `boot_proportions` and assign it to the variable `approximate_sd`.\n",
    "\n",
    "Instead of using `boot_proportions` directly, use **both** the Central Limit Theorem and the standard deviation formula above. Since you don't know the true proportions of 0s and 1s in the population, use the proportions in the sample instead (since they're likely to be similar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "approximate_sd = ...\n",
    "approximate_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2.** Compute the actual standard deviation of the array `boot_proportions`. Your answer should be close to your answer from Question 3.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_sd = ...\n",
    "exact_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3.**\n",
    "**Still without accessing `boot_proportions` in any way**, compute an approximate 95% confidence interval for the proportion of students that agreed that Carrot Cake is the worst OREO flavor. The cell below `grader.check(\"q3_3\")` draws your interval in gold below the histogram of `boot_proportions`; use that to verify that your answer looks right.\n",
    "\n",
    "*Hint*: In the past, we've used `np.percentile` on the array of bootstrapped estimates to find the bounds for the confidence interval. Now, **we're not allowed to use the bootstrapped distribution**, so we can't do it that way. But we don't need to! The Central Limit Theorem tells us that the distribution of the sample mean is normal with a certain standard deviation. We also know that 95% of the area of the normal distribution falls within a certain number of standard deviations from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_limit = ...\n",
    "upper_limit = ...\n",
    "\n",
    "# Your interval is:\n",
    "[lower_limit, upper_limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to plot your confidence interval.\n",
    "bpd.DataFrame().assign(boot_proportions = boot_proportions).plot(kind='hist', density=True, ec='w', bins=np.arange(0.15, 0.45, 0.01), figsize=(10, 5));\n",
    "plt.plot([upper_limit, lower_limit], [0, 0], color='gold', linewidth=10, label='Normal CI');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your confidence interval should make it clear that we're pretty confident that less than half of the students agreed that Carrot Cake is the worst OREO flavor. This makes sense, as the proportion of `'Agree'` opinions in the sample was only 0.25. Vanessa is pleased about this.\n",
    "\n",
    "Vanessa is considering redoing the survey with a larger sample to estimate the population proportion of `'Agree'` opinions with greater precision. She would be happy if the **standard deviation of the distribution of the sample mean were 0.006** (or less).  She'll need to take a new sample that's large enough to achieve that. Polling is time-consuming, so the sample also shouldn't be bigger than necessary.\n",
    "\n",
    "Instead of making the conservative assumption that the population standard deviation is 0.5 (the largest possible SD of a collection of 0s and 1s), she decides to assume that it's equal to the standard deviation of her first sample. That is,\n",
    "\n",
    "$$\\text{Population SD} \\approx \\text{Sample SD} = \\sqrt{(\\text{Proportion of 0s in Sample}) \\times (\\text{Proportion of 1s in Sample})}$$\n",
    "\n",
    "Under that assumption, she computes the smallest sample size necessary in order to be confident that the standard deviation of the distribution of the sample mean is at most 0.006."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4.**\n",
    "What sample size did she find? Assign your answer to the variable `new_sample_size`, which should be of type `int`.\n",
    "\n",
    "Use the fact that $$\\text{SD of Distribution of Possible Sample Means} = \\frac{\\text{Population SD}}{\\sqrt{\\text{sample size}}}$$\n",
    "\n",
    "*Hints*:\n",
    "- There is only one unknown in the equation above.\n",
    "- Think about how you should round your answer to satisfy the constraints of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample_size = ...\n",
    "new_sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.5.** Suppose Vanessa wants to be even more precise and take a sample of sufficient size such that the standard deviation of the sample mean distribution is 0.0015. Is it possible for her to do this? Choose the best answer and explanation, then assign `q3_5` to either 1, 2, 3, or 4.\n",
    "1. Yes. She can repeat the sample again until she comes across a sample with a standard deviation of 0.0015.\n",
    "2. Yes. Since the 0.0015 is a quarter of 0.006, the required sample size is a fourth of `new_sample_size`.\n",
    "3. Yes. Since the 0.0015 is a quarter of 0.006, the required sample size is four times `new_sample_size`.\n",
    "3. No, the sample size required to reach that sample mean standard deviation is larger than the number of students at UCSD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_5 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Key Concepts üîë"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.1.** How do we convert the value 116 to standard units if it comes from a data set where the mean is 133 and the standard deviation is 14? Assign `q4_1` to either 1, 2, 3, or 4.\n",
    "\n",
    "1.\n",
    "$\\dfrac{({133-116})^2}{14}$\n",
    "\n",
    "2.\n",
    "$\\dfrac{133-116}{14}$\n",
    "\n",
    "3.\n",
    "$\\dfrac{116-133}{14}$\n",
    "\n",
    "4.\n",
    "$\\dfrac{{116-133}}{\\sqrt{14}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_1 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.2.** According to Chebyshev's inequality, for any data set, at least one quarter the data falls within how many standard deviations of the mean? Assign the **smallest** correct answer to `q4_2`.\n",
    "\n",
    "1. 1.00\n",
    "2. 1.16\n",
    "3. 1.28\n",
    "4. 1.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_2 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.3.** Assign `q4_3` to a **list** of all statements below that are **always** true.\n",
    "\n",
    "\n",
    "1. An empirical histogram of the sample median of a large random sample drawn with replacement from a population will be roughly normal.\n",
    "1. An empirical histogram of the sample mean of a large random sample drawn with replacement from a population will be roughly normal.\n",
    "1. If we know the mean and SD of a distribution, we can calculate a 95% confidence interval by stepping out two standard deviations from the mean in either direction.\n",
    "1. For any distribution, at least 68% of the data falls within two standard deviations of the mean.\n",
    "1. For any distribution, 68% of the data falls within one standard deviation of the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_3 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.4.** Consider drawing a large random sample with replacement from some population. Let $x$ be the sample size such that the standard deviation of the distribution of sample means is 0.08. What sample size is required to guarantee that the standard deviation of the distribution of sample means is no more than 0.02? Assign `q4_4` to either 1, 2, 3, or 4.\n",
    "\n",
    "1. $2x$\n",
    "2. $4x$\n",
    "3. $8x$\n",
    "4. $16x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_4 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finish Line üèÅ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You are done with Homework 6 ‚Äì the final homework of the quarter! üéâ\n",
    "\n",
    "To submit your assignment:\n",
    "\n",
    "1. Select `Kernel -> Restart & Run All` to ensure that you have executed all cells, including the test cells.\n",
    "1. Read through the notebook to make sure everything is fine and all tests passed.\n",
    "1. Run the cell below to run all tests, and make sure that they all pass.\n",
    "1. Download your notebook using `File -> Download as -> Notebook (.ipynb)`, then upload your notebook to Gradescope.\n",
    "1. Stick around while the Gradescope autograder grades your work. Make sure you see that all tests have passed on Gradescope.\n",
    "1. Check that you have a confirmation email from Gradescope and save it as proof of your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
