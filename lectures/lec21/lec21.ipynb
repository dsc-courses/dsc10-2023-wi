{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Set up packages for lecture. Don't worry about understanding this code, but\n",
    "# make sure to run it if you're following along.\n",
    "import numpy as np\n",
    "import babypandas as bpd\n",
    "import pandas as pd\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "import matplotlib.pyplot as plt\n",
    "set_matplotlib_formats(\"svg\")\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "np.set_printoptions(threshold=20, precision=2, suppress=True)\n",
    "pd.set_option(\"display.max_rows\", 7)\n",
    "pd.set_option(\"display.max_columns\", 8)\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "\n",
    "# Animations\n",
    "import time\n",
    "from IPython.display import display, HTML, IFrame, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def normal_curve(x, mu=0, sigma=1):\n",
    "    return 1 / np.sqrt(2*np.pi) * np.exp(-(x - mu)**2/(2 * sigma**2))\n",
    "\n",
    "def normal_area(a, b, bars=False):\n",
    "    x = np.linspace(-4, 4, 1000)\n",
    "    y = normal_curve(x)\n",
    "    ix = (x >= a) & (x <= b)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(x, y, color='black')\n",
    "    plt.fill_between(x[ix], y[ix], color='gold')\n",
    "    if bars:\n",
    "        plt.axvline(a, color='red')\n",
    "        plt.axvline(b, color='red')\n",
    "    plt.title(f'Area between {np.round(a, 2)} and {np.round(b, 2)}')\n",
    "    plt.show()\n",
    "\n",
    "def show_clt_slides():\n",
    "    src = \"https://docs.google.com/presentation/d/e/2PACX-1vTcJd3U1H1KoXqBFcWGKFUPjZbeW4oiNZZLCFY8jqvSDsl4L1rRTg7980nPs1TGCAecYKUZxH5MZIBh/embed?start=false&loop=false&delayms=3000\"\n",
    "    width = 960\n",
    "    height = 509\n",
    "    display(IFrame(src, width, height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 21 ‚Äì The Normal Distribution, The Central Limit Theorem \n",
    "\n",
    "## DSC 10, Winter 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements\n",
    "\n",
    "- Lab 6 is due **Tuesday 3/7 at 11:59PM**.\n",
    "- Homework 6 is due **Thursday 3/7 at 11:59PM**.\n",
    "- Check out the DSC Senior Capstone Showcase on Wednesday 3/15. \n",
    "    - See how DSC majors are putting their skills to work on problems from a variety of domains.\n",
    "    - Block 1 (11AM-12:30PM): Medicine and Bioinformatics üíä, Graphs and Deep Learning üìà, Finance and Blockchain üí∞\n",
    "    - Block 2 (1-2:30PM): NLP, Sentiment Analysis, and Social Media üó£, Fairness and Causality ü§ù, Other Applications ‚öôÔ∏è\n",
    "    - [RSVP here](https://hdsishowcase.com/) by 3/13."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Check-in ‚úÖ ‚Äì Answer at [cc.dsc10.com](http://cc.dsc10.com)\n",
    "\n",
    "The Final project is due on **Tuesday 3/14 at 11:59PM** and has 8 sections. How much progress have you made?\n",
    "\n",
    "A. Not started or barely started ‚è≥  \n",
    "B. Finished 1 or 2 sections  \n",
    "C. Finished 3 or 4 sections  ‚ù§Ô∏è  \n",
    "D. Finished 5 or 6 sections  \n",
    "E. Finished 7 or 8 sections ü§Ø\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "\n",
    "- The normal distribution.\n",
    "- The Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recap: Standard units\n",
    "\n",
    "SAT scores range from 0 to 1600. The distribution of SAT scores has a mean of 950 and a standard deviation of 300. Your friend tells you that their SAT score, in standard units, is 2.5. What do you conclude?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recap: The standard normal distribution\n",
    "\n",
    "- The standard normal distribution can be thought of as a \"continuous histogram.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Like a histogram:\n",
    "    - The **area** between $a$ and $b$ is the **proportion** of values between $a$ and $b$.\n",
    "    - The total area underneath the normal curve is is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The standard normal distribution's **cumulative density function** (CDF) describes the proportion of values in the distribution less than or equal to $z$, for all values of $z$.\n",
    "    - In Python, we use the function `scipy.stats.norm.cdf`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using the normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Last time, we looked at a data set of heights and weights of 5000 adult males."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_and_weight = bpd.read_csv('data/height_and_weight.csv')\n",
    "height_and_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Both variables are roughly normal. What _benefit_ is there to knowing that the two distributions are roughly normal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Standard units and the normal distribution\n",
    "\n",
    "- **Key idea: The $x$-axis in a plot of the <u>standard</u> normal distribution is in <u>standard</u> units.**\n",
    "    - For instance, the area between -1 and 1 is the proportion of values within 1 standard deviation of the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Suppose a distribution is roughly normal. Then, these are two are approximately equal:\n",
    "    - The proportion of values in the distribution between $a$ and $b$.\n",
    "    - The area between $z(a)$ and $z(b)$ under the standard normal curve. (Recall, $z(x_i) = \\frac{x_i - \\text{mean of $x$}}{\\text{SD of $x$}}$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Proportion of heights between 65 and 70 inches\n",
    "\n",
    "Let's suppose, as is often the case, that we don't have access to the entire distribution of heights, just the mean and SD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "heights = height_and_weight.get('Height')\n",
    "height_mean = heights.mean()\n",
    "height_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_std = np.std(heights)\n",
    "height_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using just this information, we can estimate the proportion of heights between 65 and 70 inches:\n",
    "\n",
    "1. Convert 65 to standard units.\n",
    "2. Convert 70 to standard units.\n",
    "3. Use `stats.norm.cdf` to find the area between (1) and (2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = (65 - height_mean) / height_std\n",
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right = (70 - height_mean) / height_std\n",
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_area(left, right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "approximation = stats.norm.cdf(right) - stats.norm.cdf(left)\n",
    "approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Checking the approximation\n",
    "\n",
    "Since we have access to the entire set of heights, we can compute the true proportion of heights between 65 and 70 inches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True proportion of values between 65 and 70.\n",
    "height_and_weight[\n",
    "    (height_and_weight.get('Height') >= 65) &\n",
    "    (height_and_weight.get('Height') <= 70)\n",
    "].shape[0] / height_and_weight.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximation using the standard normal curve.\n",
    "approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good for an approximation! ü§©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Warning: Standardization doesn't make a distribution normal!\n",
    "\n",
    "Consider the distribution of delays from earlier in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delays = bpd.read_csv('data/delays.csv')\n",
    "delays.plot(kind='hist', y='Delay', bins=np.arange(-20.5, 210, 5), density=True, ec='w', figsize=(10, 5), title='Flight Delays')\n",
    "plt.xlabel('Delay (minutes)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution above does not look normal. It won't look normal even if we standardize it. By standardizing a distribution, all we do is move it horizontally and stretch it vertically ‚Äì the shape itself doesn't change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML('data/delay_anim.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Center and spread, revisited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Special cases\n",
    "\n",
    "- As we just discovered, the $x$-axis in the standard normal curve represents standard units.\n",
    "- Often times, we want to know the proportion of values within $z$ standard deviations of the mean.\n",
    "\n",
    "|Percent in Range | Normal Distribution |\n",
    "|---|---|\n",
    "|$\\text{mean} \\pm 1 \\: \\text{SD}$ | $\\approx 68\\%$ |\n",
    "|$\\text{mean} \\pm 2 \\: \\text{SDs}$ | $\\approx 95\\%$ |\n",
    "|$\\text{mean} \\pm 3 \\: \\text{SDs}$ | $\\approx 99.73\\%$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 68% of values are within 1 SD of the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "normal_area(-1, 1, bars=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.norm.cdf(1) - stats.norm.cdf(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that if a variable follows a normal distribution, approximately 68% of values will be within 1 SD of the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 95% of values are within 2 SDs of the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_area(-2, 2, bars=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.norm.cdf(2) - stats.norm.cdf(-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If a variable follows a normal distribution, approximately 95% of values will be within 2 SDs of the mean.\n",
    "- Consequently, 5% of values will be outside this range.\n",
    "- Since the normal curve is symmetric, \n",
    "    - 2.5% of values will be more than 2 SDs above the mean, and\n",
    "    - 2.5% of values will be more than 2 SDs below the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Chebyshev's inequality and the normal distribution\n",
    "\n",
    "- Last class, we looked at Chebyshev's inequality, which stated that the proportion of data within $z$ SDs of the mean is **at least** $1-\\frac{1}{z^2}$.\n",
    "    - This works for any distribution, and is a lower bound."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If we know that the distribution is normal, we can be even more specific:\n",
    "\n",
    "\n",
    "| Range | All Distributions (via Chebyshev's inequality) | Normal Distribution|\n",
    "|---|---|---|\n",
    "| mean $\\pm \\ 1$ SD | $\\geq 0\\%$ |$\\approx 68\\%$ |\n",
    "| mean $\\pm \\ 2$ SDs | $\\geq 75\\%$ | $\\approx 95\\%$ |\n",
    "| mean $\\pm \\ 3$ SDs | $\\geq 88.8\\%$ | $\\approx 99.73\\%$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The percentages you see for normal distributions above are approximate, but are not lower bounds.\n",
    "    - **Important**: They apply to all normal distributions, standardized or not. This is because all normal distributions are just stretched and shifted versions of the standard normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inflection points\n",
    "\n",
    "- Last class, we mentioned that the standard normal curve has inflection points at $z = \\pm 1$.\n",
    "    - An inflection point is where a curve goes from \"opening down\" üôÅ to \"opening up\" üôÇ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We know that the $x$-axis of the standard normal curve represents standard units, so the inflection points are at 1 standard deviation above and below the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This means that if a distribution is roughly normal, we can determine its standard deviation by finding the distance between each inflection point and the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Inflection points\n",
    "\n",
    "Remember: The distribution of heights is roughly normal, but it is _not_ a _standard_ normal distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "height_and_weight.plot(kind='hist', y='Height', density=True, ec='w', bins=40, alpha=0.8, figsize=(10, 5));\n",
    "plt.xticks(np.arange(60, 78, 2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The center appears to be around 69.\n",
    "- The inflection points appear to be around 66 and 72.\n",
    "- So, the standard deviation is roughly 72 - 69 = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(height_and_weight.get('Height'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Central Limit Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Back to flight delays ‚úàÔ∏è\n",
    "\n",
    "The distribution of flight delays that we've been looking at is _not_ roughly normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delays = bpd.read_csv('data/delays.csv')\n",
    "delays.plot(kind='hist', y='Delay', bins=np.arange(-20.5, 210, 5), density=True, ec='w', figsize=(10, 5), title='Population Distribution of Flight Delays')\n",
    "plt.xlabel('Delay (minutes)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delays.get('Delay').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Empirical distribution of a sample statistic\n",
    "\n",
    "- Before we started discussing center, spread, and the normal distribution, our focus was on bootstrapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We used the bootstrap to estimate **the distribution of a sample statistic (e.g. sample mean or sample median)**, using just a single sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We did this to construct confidence intervals for a population parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Important**: For now, we'll suppose our parameter of interest is the population mean, **so we're interested in estimating the distribution of the sample mean**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Empirical distribution of the sample mean \n",
    "\n",
    "Since we have access to the population of flight delays, let's remind ourselves what the distribution of the sample mean looks like by drawing samples repeatedly from the population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- This is **not bootstrapping**.\n",
    "- This is also **not practical**. If we had access to a population, we wouldn't need to understand the distribution of the sample mean ‚Äì we'd be able to compute the population mean directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sample_means = np.array([])\n",
    "repetitions = 2000\n",
    "\n",
    "for i in np.arange(repetitions):\n",
    "    sample = delays.sample(500)\n",
    "    sample_mean = sample.get('Delay').mean()\n",
    "    sample_means = np.append(sample_means, sample_mean)\n",
    "    \n",
    "sample_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpd.DataFrame().assign(sample_means=sample_means).plot(kind='hist', density=True, ec='w', alpha=0.65, bins=20, figsize=(10, 5));\n",
    "plt.scatter([sample_means.mean()], [-0.005], marker='^', color='green', s=250)\n",
    "plt.axvline(sample_means.mean(), color='green', label=f'mean={np.round(sample_means.mean(), 2)}', linewidth=4)\n",
    "plt.xlim(5, 30)\n",
    "plt.ylim(-0.013, 0.26)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice that this distribution is roughly normal, even though the population distribution was not! This distribution is centered at the population mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Central Limit Theorem\n",
    "\n",
    "> The Central Limit Theorem (CLT) says that the probability distribution of the **sum or mean** of a large random sample drawn with replacement will be roughly normal, regardless of the distribution of the population from which the sample is drawn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "While the formulas we're about to introduce only work for sample means, it's important to remember that the statement above also holds true for sample sums."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Characteristics of the distribution of the sample mean\n",
    "\n",
    "- **Shape**: The CLT says that the distribution of the sample mean is roughly normal, no matter what the population looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Center**: This distribution is centered at the population mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Spread**: What is the standard deviation of the distribution of the sample mean? How is it impacted by the sample size?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Changing the sample size\n",
    "\n",
    "The function `sample_mean_delays` takes in an integer `sample_size`, and:\n",
    "1. Takes a sample of size `sample_size` directly from the population.\n",
    "2. Computes the mean of the sample.\n",
    "3. Repeats steps 1 and 2 above 2000 times, and returns an array of the resulting means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def sample_mean_delays(sample_size):\n",
    "    sample_means = np.array([])\n",
    "    for i in np.arange(2000):\n",
    "        sample = delays.sample(sample_size)\n",
    "        sample_mean = sample.get('Delay').mean()\n",
    "        sample_means = np.append(sample_means, sample_mean)\n",
    "    return sample_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's call `sample_mean_delays` on several values of `sample_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sample_means = {}\n",
    "sample_sizes = [5, 10, 50, 100, 200, 400, 800, 1600]\n",
    "\n",
    "for size in sample_sizes:\n",
    "    sample_means[size] = sample_mean_delays(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the resulting distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the resulting distributions.\n",
    "bins = np.arange(5, 30, 0.5)\n",
    "for size in sample_sizes:\n",
    "    bpd.DataFrame().assign(data=sample_means[size]).plot(kind='hist', bins=bins, density=True, ec='w', title=f'Distribution of the Sample Mean for Samples of Size {size}', figsize=(8, 4))\n",
    "    plt.legend('');\n",
    "    plt.show()\n",
    "    time.sleep(1.5)\n",
    "    if size != sample_sizes[-1]:\n",
    "        clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What do you notice? ü§î"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Standard deviation of the distribution of the sample mean\n",
    "\n",
    "- As we increase our sample size, the distribution of the sample mean gets narrower, and so its standard deviation decreases.\n",
    "- Can we determine exactly how much it decreases by?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Compute the standard deviation of each distribution.\n",
    "sds = np.array([])\n",
    "for size in sample_sizes:\n",
    "    sd = np.std(sample_means[size])\n",
    "    sds = np.append(sds, sd)\n",
    "sds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "observed = bpd.DataFrame().assign(\n",
    "    SampleSize=sample_sizes,\n",
    "    StandardDeviation=sds\n",
    ")\n",
    "\n",
    "observed.plot(kind='scatter', x='SampleSize', y='StandardDeviation', s=70, title=\"Standard Deviation of the Distribution of the Sample Mean vs. Sample Size\", figsize=(10, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It appears that as the sample size increases, the standard deviation of the distribution of the sample mean _decreases quickly_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Standard deviation of the distribution of the sample mean\n",
    "\n",
    "- As we increase our sample size, the distribution of the sample mean gets narrower, and so its standard deviation decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Here's the mathematical relationship describing this phenomenon:\n",
    "\n",
    "$$\\text{SD of Distribution of Possible Sample Means} = \\frac{\\text{Population SD}}{\\sqrt{\\text{sample size}}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This is sometimes called the **square root law**. Its proof is outside the scope of this class; you'll see it if you take upper-division probability courses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This says that when we take large samples, the distribution of the sample mean is narrow, and so the sample mean is typically pretty close to the population mean. As expected, bigger samples tend to yield better estimates of the population mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Note:** This is **not** saying anything about the standard deviation of a sample itself! It is a statement about the distribution of all possible sample means. If we increase the size of the sample we're taking:\n",
    "    - It **is not true** ‚ùå that the SD of our sample will decrease.\n",
    "    - It **is true** ‚úÖ that the SD of the distribution of all possible sample means of that size will decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recap: Distribution of the sample mean\n",
    "\n",
    "If we were to take many, many samples of the same size from a population, and take the mean of each sample, the distribution of the sample mean will have the following characteristics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Shape**: The distribution will be roughly normal, regardless of the shape of the population distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Center**: The distribution will be centered at the population mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Spread**: The distribution's standard deviation will be described by the square root law: \n",
    "\n",
    "$$\\text{SD of Distribution of Possible Sample Means} = \\frac{\\text{Population SD}}{\\sqrt{\\text{sample size}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**üö® Practical Issue**: The mean and standard deviation of the distribution of the sample mean both depend on the original population, but we typically **don't have access to the population**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bootstrapping vs. the CLT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The goal of bootstrapping was to estimate the distribution of a sample statistic (e.g. the sample mean), given just a single sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The CLT describes the distribution of the sample mean, but it depends on information about the population (i.e. the population mean and population SD)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Idea**: The sample mean and SD are likely to be close to the population mean and SD. So, use them as approximations in the CLT!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As a result, **we can approximate the distribution of the sample mean, given just a single sample, without ever having to bootstrap!**\n",
    "    - In other words, the CLT is a shortcut to bootstrapping!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Estimating the distribution of the sample mean by bootstrapping\n",
    "\n",
    "Let's take a single sample of size 500 from `delays`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "my_sample = delays.sample(500)\n",
    "my_sample.get('Delay').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Before today, to estimate the distribution of the sample mean using just this sample, we'd bootstrap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_means = np.array([])\n",
    "repetitions = 2000\n",
    "\n",
    "for i in np.arange(repetitions):\n",
    "    resample = my_sample.sample(500, replace=True)\n",
    "    resample_mean = resample.get('Delay').mean()\n",
    "    resample_means = np.append(resample_means, resample_mean)\n",
    "    \n",
    "resample_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpd.DataFrame().assign(resample_means=resample_means).plot(kind='hist', density=True, ec='w', alpha=0.65, bins=20, figsize=(10, 5));\n",
    "plt.scatter([resample_means.mean()], [-0.005], marker='^', color='green', s=250)\n",
    "plt.axvline(resample_means.mean(), color='green', label=f'mean={np.round(resample_means.mean(), 2)}', linewidth=4)\n",
    "plt.xlim(7, 20)\n",
    "plt.ylim(-0.015, 0.35)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The CLT tells us what this distribution will look like, without having to bootstrap!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using the CLT with just a single sample\n",
    "\n",
    "Suppose all we have access to in practice is a single \"original sample.\" If we were to take many, many samples of the same size from this original sample, and take the mean of each resample, the distribution of the (re)sample mean will have the following characteristics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Shape**: The distribution will be roughly normal, regardless of the shape of the original sample's distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Center**: The distribution will be centered at the **original sample's mean**, which should be close to the population's mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Spread**: The distribution's standard deviation will be described by the square root law: \n",
    "\n",
    "$$\\begin{align}\n",
    "\\text{SD of Distribution of Possible Sample Means} &= \\frac{\\text{Population SD}}{\\sqrt{\\text{sample size}}} \\\\\n",
    "&\\approx \\boxed{\\frac{\\textbf{Sample SD}}{\\sqrt{\\text{sample size}}}}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's test this out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using the CLT with just a single sample\n",
    "\n",
    "Using just the original sample, `my_sample`, we estimate that the distribution of the sample mean has the following mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samp_mean_mean = my_sample.get('Delay').mean()\n",
    "samp_mean_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the following standard deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_mean_sd = np.std(my_sample.get('Delay')) / np.sqrt(my_sample.shape[0])\n",
    "samp_mean_sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's draw a normal distribution with the above mean and standard deviation, and overlay the bootstrapped distribution from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_x = np.linspace(7, 20)\n",
    "norm_y = normal_curve(norm_x, mu=samp_mean_mean, sigma=samp_mean_sd)\n",
    "bpd.DataFrame().assign(Bootstrapping=resample_means).plot(kind='hist', density=True, ec='w', alpha=0.65, bins=20, figsize=(10, 5));\n",
    "plt.plot(norm_x, norm_y, color='black', linestyle='--', linewidth=4, label='CLT')\n",
    "plt.title('Distribution of the Sample Mean, Using Two Methods')\n",
    "plt.xlim(7, 20)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Key takeaway**: Given just a single sample, we can use the CLT to estimate the distribution of the sample mean, **without bootstrapping**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "show_clt_slides()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Confidence intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Confidence intervals\n",
    "\n",
    "- Previously, we bootstrapped to construct confidence intervals.\n",
    "    - Strategy: Collect one sample, repeatedly resample from it, calculate the statistic on each resample, and look at middle 95% of resampled statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- But, **if our statistic is the mean**, we can use the CLT.\n",
    "    - Computationally cheaper - no simulation required!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In both cases, we use just a single sample to construct our confidence interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Constructing a 95% confidence interval via the bootstrap\n",
    "\n",
    "Earlier, we bootstrapped `my_sample` to generate 2000 resample means. One approach to computing a confidence interval for the population mean involves taking the middle 95% of this distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_boot = np.percentile(resample_means, 2.5)\n",
    "right_boot = np.percentile(resample_means, 97.5)\n",
    "[left_boot, right_boot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bpd.DataFrame().assign(resample_means=resample_means).plot(kind='hist', y='resample_means', alpha=0.65, bins=20, density=True, ec='w', figsize=(10, 5), title='Distribution of Bootstrapped Sample Means');\n",
    "plt.plot([left_boot, right_boot], [0, 0], color='gold', linewidth=10, label='95% bootstrap-based confidence interval');\n",
    "plt.xlim(7, 20);\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Middle 95% of a normal distribution\n",
    "\n",
    "Using the CLT and `my_sample` only, we estimate that the sample mean's distribution is the following normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "norm_x = np.linspace(7, 20)\n",
    "norm_y = normal_curve(norm_x, mu=samp_mean_mean, sigma=samp_mean_sd)\n",
    "plt.plot(norm_x, norm_y, color='black', linestyle='--', linewidth=4, label='Distribution of the Sample Mean (via the CLT)')\n",
    "plt.xlim(7, 20)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Question**: What interval on the $x$-axis captures the **middle 95%** of the above distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recap: Normal distributions\n",
    "\n",
    "As we saw earlier, if a variable is roughly normal, then approximately 95% of its values are within 2 standard deviations of its mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_area(-2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.norm.cdf(2) - stats.norm.cdf(-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's use this fact here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Computing a 95% confidence interval via the CLT\n",
    "\n",
    "- Recall: Approximately 95% of the normal curve's area falls within $\\pm$ 2 SDs of the mean.\n",
    "- Don't confuse the **sample SD** with the **SD of the sample mean's distribution**!\n",
    "\n",
    "$$\\text{SD of Distribution of Possible Sample Means} \\approx \\frac{\\text{Sample SD}}{\\sqrt{\\text{sample size}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_delays = my_sample.get('Delay')\n",
    "left_normal = my_delays.mean() - 2 * np.std(my_delays) / np.sqrt(500)\n",
    "right_normal = my_delays.mean() + 2 * np.std(my_delays) / np.sqrt(500)\n",
    "[left_normal, right_normal]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing the CLT-based confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "norm_x = np.linspace(7, 20)\n",
    "norm_y = normal_curve(norm_x, mu=samp_mean_mean, sigma=samp_mean_sd)\n",
    "plt.plot(norm_x, norm_y, color='black', linestyle='--', linewidth=4, label='Distribution of the Sample Mean (via the CLT)')\n",
    "plt.xlim(7, 20)\n",
    "plt.ylim(0, 0.41)\n",
    "plt.plot([left_normal, right_normal], [0, 0], color='#8f6100', linewidth=10, label='95% CLT-based confidence interval')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing confidence intervals\n",
    "\n",
    "We've constructed two confidence intervals for the population mean:\n",
    "\n",
    "One using bootstrapping,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[left_boot, right_boot]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "and one using the CLT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[left_normal, right_normal]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both cases, we only used information in `my_sample`, not the population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recap: Confidence intervals for the population mean\n",
    "\n",
    "An approximate 95% confidence interval for the population mean is given by\n",
    "\n",
    "$$\n",
    "\\left[\\text{sample mean} - 2\\cdot \\frac{\\text{sample SD}}{\\sqrt{\\text{sample size}}},\n",
    "\\text{sample mean} + 2\\cdot \\frac{\\text{sample SD}}{\\sqrt{\\text{sample size}}}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "This CI doesn't require bootstrapping, and it only requires three numbers ‚Äì the sample mean, the sample SD, and the sample size!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bootstrap vs. the CLT\n",
    "\n",
    "The bootstrap still has its uses!\n",
    "\n",
    "| | Bootstrap | CLT |\n",
    "| --- | --- | --- |\n",
    "| **Pro** | Works for many sample statistics <br> (mean, median, standard deviation). | Only requires 3 numbers ‚Äì <br>the sample mean, sample SD, and sample size. |\n",
    "| **Con** | Very computationally expensive (requires drawing many, <br> many samples from the original sample). | Only works for the sample mean (and sum). | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary, next time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- If a variable is roughly normally distributed, then approximately 68% of its values are within 1 SD of the mean, and approximately 95% of its values are within 2 SDs of the mean.\n",
    "- The Central Limit Theorem (CLT) says that the probability distribution of the **sum or mean** of a large random sample drawn with replacement will be roughly normal, regardless of the distribution of the population from which the sample is drawn.\n",
    "- In the case of the sample mean, the CLT says:\n",
    "    - The distribution of the sample mean is centered at the population mean.\n",
    "    - The SD of the distribution of the sample mean is $\\frac{\\text{Population SD}}{\\sqrt{\\text{sample size}}}$.\n",
    "- To create a confidence interval for the population mean, we can use the CLT instead of bootstrapping!\n",
    "    - A 95% confidence interval for the population mean is given by \n",
    "    \n",
    "$$\n",
    "\\left[\\text{sample mean} - 2\\cdot \\frac{\\text{sample SD}}{\\sqrt{\\text{sample size}}},\n",
    "\\text{sample mean} + 2\\cdot \\frac{\\text{sample SD}}{\\sqrt{\\text{sample size}}}\n",
    "\\right].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Next time\n",
    "\n",
    "- Using CLT-based confidence intervals for hypothesis tests.\n",
    "- Creating CLT-based confidence intervals for population _proportions_.\n",
    "    - Proportions are means!\n",
    "- Choosing sample sizes.\n",
    "    - We want to construct a confidence interval whose width is at most $w$. How many people should we sample?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "livereveal": {
   "scroll": true,
   "transition": "none"
  },
  "rise": {
   "enable_chalkboard": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
