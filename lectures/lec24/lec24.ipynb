{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Set up packages for lecture. Don't worry about understanding this code, but\n",
    "# make sure to run it if you're following along.\n",
    "import numpy as np\n",
    "import babypandas as bpd\n",
    "import pandas as pd\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "set_matplotlib_formats(\"svg\")\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "np.set_printoptions(threshold=20, precision=2, suppress=True)\n",
    "pd.set_option(\"display.max_rows\", 7)\n",
    "pd.set_option(\"display.max_columns\", 8)\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# New minimize function (wrapper around scipy.optimize.minimize)\n",
    "from inspect import signature\n",
    "from scipy import optimize\n",
    "\n",
    "def minimize(function):\n",
    "    n_args = len(signature(function).parameters)\n",
    "    initial = np.zeros(n_args)\n",
    "    return optimize.minimize(lambda x: function(*x), initial).x\n",
    "\n",
    "# All of the following code is for visualization.\n",
    "def plot_regression_line(df, x, y, margin=.02):\n",
    "    '''Computes the slope and intercept of the regression line between columns x and y in df (in original units) and plots it.'''\n",
    "    m = slope(df, x, y)\n",
    "    b = intercept(df, x, y)\n",
    "    \n",
    "    df.plot(kind='scatter', x=x, y=y, s=100, figsize=(10, 5), label='original data')\n",
    "    left = df.get(x).min()*(1 - margin)\n",
    "    right = df.get(x).max()*(1 + margin)\n",
    "    domain = np.linspace(left, right, 10)\n",
    "    plt.plot(domain, m*domain + b, color='orange', label='regression line', lw=4)\n",
    "    plt.suptitle(format_equation(m, b), fontsize=18)\n",
    "    plt.legend();\n",
    "    \n",
    "def format_equation(m, b):\n",
    "    if b > 0:\n",
    "        return r'$y = %.2fx + %.2f$' % (m, b)\n",
    "    elif b == 0:\n",
    "        return r'$y = %.2fx' % m\n",
    "    else:\n",
    "        return r'$y = %.2fx %.2f$' % (m, b)\n",
    "    \n",
    "def plot_errors(df, m, b, ax=None):\n",
    "    x = df.get('x')\n",
    "    y = m * x + b\n",
    "    df.plot(kind='scatter', x='x', y='y', s=100, label='original data', ax=ax, figsize=(10, 5) if ax is None else None)\n",
    "    \n",
    "    if ax:\n",
    "        plotter = ax\n",
    "    else:\n",
    "        plotter = plt\n",
    "    \n",
    "    plotter.plot(x, y, color='orange', lw=4)\n",
    "    \n",
    "    for k in np.arange(df.shape[0]):\n",
    "        xk = df.get('x').iloc[k]\n",
    "        yk = np.asarray(y)[k]\n",
    "        if k == df.shape[0] - 1:\n",
    "            plotter.plot([xk, xk], [yk, df.get('y').iloc[k]], linestyle=(0, (1, 1)), c='r', lw=4, label='errors')\n",
    "        else:\n",
    "            plotter.plot([xk, xk], [yk, df.get('y').iloc[k]], linestyle=(0, (1, 1)), c='r', lw=4)\n",
    "    \n",
    "    plt.title(format_equation(m, b), fontsize=18)\n",
    "    plt.xlim(50, 90)\n",
    "    plt.ylim(40, 100)\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 24 ‚Äì Regression and Least Squares\n",
    "\n",
    "## DSC 10, Winter 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements\n",
    "\n",
    "- Lab 7 is due **tomorrow at 11:59 PM**.\n",
    "    - We'll drop the lowest lab, so you may not need to submit this if you've done well on all the others. However, this is the only assignment on regression, which will be tested on the final exam, so it's a good idea to do it for practice at least.\n",
    "- The Final Project is due on **Tuesday 3/14 at 11:59 PM**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Check-in ‚úÖ ‚Äì Answer at [cc.dsc10.com](http://cc.dsc10.com)\n",
    "\n",
    "The Final Project is due on **Tuesday 3/14 at 11:59 PM** and has 8 sections. How much progress have you made?\n",
    "\n",
    "A. Not started or barely started ‚è≥  \n",
    "B. Finished 1 or 2 sections  \n",
    "C. Finished 3 or 4 sections  ‚ù§Ô∏è  \n",
    "D. Finished 5 or 6 sections  \n",
    "E. Finished 7 or 8 sections ü§Ø\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "\n",
    "- The regression line, in standard units.\n",
    "- The regression line, in original units.\n",
    "- Outliers.\n",
    "- Errors in prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The regression line, in standard units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Predicting heights  üë™ üìè\n",
    "\n",
    "Recall, in the last lecture, we aimed to use a mother's height to predict her adult son's height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galton = bpd.read_csv('data/galton.csv')\n",
    "male_children = galton[galton.get('gender') == 'male']\n",
    "mom_son = bpd.DataFrame().assign(mom = male_children.get('mother'), \n",
    "                                 son = male_children.get('childHeight'))\n",
    "mom_son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mom_son.plot(kind='scatter', x='mom', y='son', figsize=(10, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Correlation\n",
    "\n",
    "Recall, the correlation coefficient $r$ of two variables $x$ and $y$ is defined as the \n",
    "- **average** value of the \n",
    "- **product** of $x$ and $y$\n",
    "- when both are measured in **standard units**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_units(any_numbers):\n",
    "    \"Convert a sequence of numbers to standard units.\"\n",
    "    return (any_numbers - any_numbers.mean()) / np.std(any_numbers)\n",
    "\n",
    "def correlation(df, x, y):\n",
    "    \"Computes the correlation between column x and column y of df.\"\n",
    "    return (standard_units(df.get(x)) * standard_units(df.get(y))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_mom_son = correlation(mom_son, 'mom', 'son')\n",
    "r_mom_son"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The regression line\n",
    "\n",
    "- The regression line is the line through $(0,0)$ with slope $r$, when both variables are measured in **standard units**.\n",
    "\n",
    "<center><img src='data/regression-line.png' width=30%></center>\n",
    "\n",
    "- We use the regression line to make predictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Making predictions in standard units\n",
    "\n",
    "<center><img src='data/regression-line.png' width=30%></center>\n",
    "\n",
    "- If $r = 0.32$, and the given $x$ is $2$ in standard units, then the prediction for $y$ is $0.64$ standard units.\n",
    "    - The regression line predicts that a mother whose height is $2$ SDs above average has a son whose height is $0.64$ SDs above average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We always _predict_ that a son will be somewhat **closer to average** in height than his mother.\n",
    "    - This is a consequence of the slope $r$ having magnitude less than 1.\n",
    "    - This effect is called **regression to the mean**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The regression line passes through the origin $(0, 0)$ in standard units. This means that, no matter what $r$ is, **for an average $x$ value, we predict an average $y$ value**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Making predictions in original units\n",
    "\n",
    "Of course, we'd like to be able to predict a son's height in inches, not just in standard units. Given a mother's height in inches, here's how we'll predict her son's height in inches:\n",
    "1. Convert the mother's height from inches to standard units.\n",
    "\n",
    "$$x_{i \\: \\text{(su)}} = \\frac{x_i - \\text{mean of $x$}}{\\text{SD of $x$}}$$\n",
    "\n",
    "2. Multiply by the correlation coefficient to predict the son's height in standard units.\n",
    "\n",
    "$$\\text{predicted } y_{i \\: \\text{(su)}} = r \\cdot x_{i \\: \\text{(su)}}$$\n",
    "\n",
    "3. Convert the son's predicted height from standard units back to inches.\n",
    "\n",
    "$$\\text{predicted } y_i = \\text{predicted } y_{i \\: \\text{(su)}} \\cdot \\text{SD of $y$} + \\text{mean of $y$}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mom_mean = mom_son.get('mom').mean()\n",
    "mom_sd = np.std(mom_son.get('mom'))\n",
    "son_mean = mom_son.get('son').mean()\n",
    "son_sd = np.std(mom_son.get('son'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def predict_with_r(mom):\n",
    "    \"\"\"Return a prediction for the height of a son whose mother has height mom, \n",
    "    using linear regression.\n",
    "    \"\"\"\n",
    "    mom_su = (mom - mom_mean) / mom_sd\n",
    "    son_su = r_mom_son * mom_su\n",
    "    return son_su * son_sd + son_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_with_r(68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_with_r(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "preds = mom_son.assign(\n",
    "    predicted_height=mom_son.get('mom').apply(predict_with_r)\n",
    ")\n",
    "ax = preds.plot(kind='scatter', x='mom', y='son', title='Regression line predictions, in original units', figsize=(10, 5), label='original data')\n",
    "preds.plot(kind='line', x='mom', y='predicted_height', ax=ax, color='orange', label='regression line', lw=4);\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Concept Check ‚úÖ ‚Äì Answer at [cc.dsc10.com](http://cc.dsc10.com) \n",
    "\n",
    "A course has a midterm (mean 80, standard deviation 15) and a really hard final (mean 50, standard deviation 12).\n",
    "\n",
    "If the scatter plot comparing midterm & final scores for students looks linearly associated with correlation 0.75, then what is the predicted final exam score for a student who received a 90 on the midterm?\n",
    "\n",
    "- A. 54\n",
    "- B. 56\n",
    "- C. 58\n",
    "- D. 60\n",
    "- E. 62"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The regression line, in original units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reflection\n",
    "\n",
    "Each time we wanted to predict the height of an adult son given the height of a mother, we had to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Convert the mother's height from inches to standard units.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. Multiply by the correlation coefficient to predict the son's height in standard units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. Convert the son's predicted height from standard units back to inches.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is inconvenient ‚Äì wouldn't it be great if we could express the regression line itself in inches?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### From standard units to original units\n",
    "\n",
    "When $x$ and $y$ are in standard units, the regression line is given by\n",
    "\n",
    "<center><img src='data/regression-line.png' width=30%></center>\n",
    "\n",
    "What is the regression line when $x$ and $y$ are in their original units?\n",
    "\n",
    "<center><img src=\"data/original_standard.png\" width=50%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The regression line in original units\n",
    "\n",
    "- We can work backwards from the relationship \n",
    "$$\\text{predicted } y_{\\text{(su)}} = r \\cdot x_{\\text{(su)}}$$\n",
    "to find the line in original units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\frac{\\text{predicted } y - \\text{mean of }y}{\\text{SD of }y} = r \\cdot \\frac{x - \\text{mean of } x}{\\text{SD of }x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that $r, \\text{mean of } x$, $\\text{mean of } y$, $\\text{SD of } x$, and $\\text{SD of } y$ are constants ‚Äì if you have a DataFrame with two columns, you can determine all 5 values.\n",
    "- Re-arranging the above equation into the form $\\text{predicted } y = mx + b$ yields the formulas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$m = r \\cdot \\frac{\\text{SD of } y}{\\text{SD of }x}, \\: \\: b = \\text{mean of } y - m \\cdot \\text{mean of } x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $m$ is the slope of the regression line and $b$ is the intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's implement these formulas in code and try them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def slope(df, x, y):\n",
    "    \"Returns the slope of the regression line between columns x and y in df (in original units).\"\n",
    "    r = correlation(df, x, y)\n",
    "    return r * np.std(df.get(y)) / np.std(df.get(x))\n",
    "\n",
    "def intercept(df, x, y):\n",
    "    \"Returns the intercept of the regression line between columns x and y in df (in original units).\"\n",
    "    return df.get(y).mean() - slope(df, x, y) * df.get(x).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we compute the slope and intercept of the regression line between mothers' heights and sons' heights (in inches)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_heights = slope(mom_son, 'mom', 'son')\n",
    "m_heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_heights = intercept(mom_son, 'mom', 'son')\n",
    "b_heights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So, the regression line is\n",
    "\n",
    "$$\\text{predicted son's height} = 0.365 \\cdot \\text{mother's height} + 45.858$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def predict_son(mom):\n",
    "    return m_heights * mom + b_heights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What's the predicted height of a son whose mother is 62 inches tall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_son(62)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What if the mother is 55 inches tall? 73 inches tall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_son(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_son(73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.arange(57, 72)\n",
    "ys = predict_son(xs)\n",
    "mom_son.plot(kind='scatter', x='mom', y='son', figsize=(10, 5), title='Regression line predictions, in original units', label='original data');\n",
    "plt.plot(xs, ys, color='orange', lw=4, label='regression line')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The effect of outliers on correlation\n",
    "\n",
    "Consider the dataset below. What is the correlation between $x$ and $y$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier = bpd.read_csv('data/outlier.csv')\n",
    "outlier.plot(kind='scatter', x='x', y='y', s=100, figsize=(10, 5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "correlation(outlier, 'x', 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regression_line(outlier, 'x', 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Removing the outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "without_outlier = outlier[outlier.get('y') > 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "correlation(without_outlier, 'x', 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regression_line(without_outlier, 'x', 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Takeaway**: Even a single outlier can have a massive impact on the correlation, and hence the regression line. Look for these before performing regression. **Always visualize first!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Errors in prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Motivation\n",
    "\n",
    "- We've presented the regression line in standard units as the line through the origin with slope $r$, given by $\\text{predicted } y_{\\text{(su)}} = r \\cdot x_{\\text{(su)}}$. Then, we used this equation to find a formula for the regression line in original units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In examples we've seen so far, the regression line seems to fit our data pretty well.\n",
    "    - But how well? \n",
    "    - What makes the regression line good?\n",
    "    - Would another line be better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Without the outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier.plot(kind='scatter', x='x', y='y', s=100, figsize=(10, 5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_no_outlier = slope(without_outlier, 'x', 'y')\n",
    "b_no_outlier = intercept(without_outlier, 'x', 'y')\n",
    "\n",
    "m_no_outlier, b_no_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_errors(without_outlier, m_no_outlier, b_no_outlier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We think our regression line is pretty good because most data points are pretty close to the regression line. The red lines are quite short."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Measuring the error in prediction\n",
    "\n",
    "$$\\text{error} = \\text{actual value} - \\text{prediction}$$\n",
    "\n",
    "- Typically, some errors are positive and some negative.\n",
    "    - What does a positive error mean? What about a negative error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To measure the rough size of the errors, for a particular set of predictions:\n",
    "    1. Square the errors so that they don't cancel each other out.\n",
    "    2. Take the mean of the squared errors.\n",
    "    3. Take the square root to fix the units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This is called **root mean square error** (RMSE).\n",
    "    - Notice the similarities to computing the SD!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Root mean squared error (RMSE) of the regression line's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = without_outlier.assign(pred=m_no_outlier * without_outlier.get('x') + b_no_outlier)\n",
    "predictions = predictions.assign(diffs=predictions.get('y') - predictions.get('pred'))\n",
    "predictions = predictions.assign(sq_diffs=predictions.get('diffs') ** 2)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(predictions.get('sq_diffs').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The RMSE of the regression line's predictions is about 2.2. Is this big or small, relative to the predictions of other lines? ü§î"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Root mean squared error (RMSE) in an arbirtrary line's predictions\n",
    "\n",
    "- We've been using the regression line to make predictions. But we could use a different line!\n",
    "    - To make a prediction for `x` using an arbitrary line defined by `slope` and `intercept`, compute `x * slope + intercept`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For this dataset, if we choose a **different line**, we will end up with different predictions, and hence a **different RMSE**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(slope, intercept):\n",
    "    '''Calculates the RMSE of the line with the given slope and intercept, \n",
    "    using the 'x' and 'y' columns of without_outlier.'''\n",
    "\n",
    "    # The true values of y.\n",
    "    true = without_outlier.get('y')\n",
    "    \n",
    "    # The predicted values of y, from plugging the x values from the \n",
    "    # given DataFrame into the line with the given slope and intercept.\n",
    "    predicted = slope * without_outlier.get('x') + intercept\n",
    "    \n",
    "    return np.sqrt(((true - predicted) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that our function works on the regression line.\n",
    "rmse(m_no_outlier, b_no_outlier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's compute the RMSEs of several different lines on the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Experiment by changing one of these!\n",
    "lines = [(1.2, -15), (0.75, 11.5), (-0.4, 100)]\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(14, 4))\n",
    "for i, line in enumerate(lines):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    m, b = line\n",
    "    plot_errors(without_outlier, m, b, ax=ax[i])\n",
    "    ax[i].set_title(format_equation(m, b) + f'\\nRMSE={np.round(rmse(m, b), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Finding the \"best\" prediction line by minimizing RMSE\n",
    "\n",
    "- RMSE describes how well a line fits the data. **The lower the RMSE of a line is, the better it fits the data**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There are infinitely many slopes and intercepts, and thus infinitely many RMSEs. How do we find which combination of slope and intercept have the lowest RMSE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If you take DSC 40A, you'll learn how to do this using calculus. For now, we'll use a function ‚Äì `minimize`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: `minimize`\n",
    "\n",
    "- The function `minimize` takes in a function as an argument, and returns the inputs to the function that produce the smallest output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For instance, we know that the minimizing input to the function $f(x) = (x - 5)^2 + 4$ is $x = 5$. `minimize` can find this, too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return (x - 5) ** 2 + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The `minimize` function uses calculus and intelligent trial-and-error to find these inputs; you don't need to know how it works under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Finding the \"best\" prediction line by minimizing RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use `minimize` on `rmse`, to find the slope and intercept of the line with the smallest RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest_rmse_line = minimize(rmse)\n",
    "smallest_rmse_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_smallest_rmse = smallest_rmse_line[0]\n",
    "b_smallest_rmse = smallest_rmse_line[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Do these numbers look familiar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Coincidence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The slope and intercept with the smallest RMSE, from our call to minimize.\n",
    "m_smallest_rmse, b_smallest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The slope and intercept according to our regression line formulas.\n",
    "slope(without_outlier, 'x', 'y'), intercept(without_outlier, 'x', 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The slopes and intercepts we got using both approaches look awfully similar... üëÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The regression line is the best line!\n",
    "\n",
    "- It turns out that the regression line we defined before before minimizes the root mean squared error (RMSE) among all lines.\n",
    "\n",
    "$$m = r \\cdot \\frac{\\text{SD of } y}{\\text{SD of }x}$$\n",
    "\n",
    "$$b = \\text{mean of } y - m \\cdot \\text{mean of } x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It is the **best** line, regardless of what our data looks like!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- All equivalent names:\n",
    "    - Line of ‚Äúbest fit‚Äù.\n",
    "    - Least squares line.\n",
    "    - Regression line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The technique of finding the slope and intercept that have the lowest RMSE is called the **method of least squares**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Quality of fit\n",
    "\n",
    "- The regression line describes the \"best linear fit\" for a given dataset.\n",
    "- The formulas for the slope and intercept work no matter what the shape of the data is.\n",
    "- But the line is only meaningful if the relationship between $x$ and $y$ is roughly linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Non-linear data\n",
    "\n",
    "What's the regression line for this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(23)\n",
    "x2 = bpd.DataFrame().assign(\n",
    "    x=np.arange(-6, 6.1, 0.5) + np.random.normal(size=25), \n",
    "    y=np.arange(-6, 6.1, 0.5)**2 + np.random.normal(size=25)\n",
    ")\n",
    "x2.plot(kind='scatter', x='x', y='y', s=100, figsize=(10, 5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regression_line(x2, 'x', 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line doesn't fit the data at all!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary, next time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- The regression line in original units is $\\text{predicted } y = mx + b$, where\n",
    "\n",
    "$$m = r \\cdot \\frac{\\text{SD of } y}{\\text{SD of }x}$$\n",
    "\n",
    "$$b = \\text{mean of } y - m \\cdot \\text{mean of } x$$\n",
    "- This line is very sensitive to outliers.\n",
    "- This line has the lowest root mean squared error (RMSE) of all possible lines.\n",
    "    - It is the \"line of best fit\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Next time\n",
    "\n",
    "- As we saw, the regression line is the best *line* to fit the data, but not all data is linear. \n",
    "- How do we determine whether fitting a line even makes sense for our dataset?\n",
    "- When we use regression, we're making predictions based on data in a sample. What if we had a different sample?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "livereveal": {
   "scroll": true,
   "transition": "none"
  },
  "rise": {
   "enable_chalkboard": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
